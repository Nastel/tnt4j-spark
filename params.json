{"name":"TNT4J-Spark","tagline":"Track and Trace for Apache Spark","body":"## About TNT4J-Spark\r\nTrack and Trace for Apache Spark. TNT4J-Spark provides an implementation of `SparkListener` for `SparkContext`.\r\nTNT4J-Spark allows developers to track execution, measure performance and help with diagnostics of your Spark applications.\r\n\r\n### Why TNT4J-Spark?\r\n* Track and Trace Spark application execution @ runtime\r\n* Measure performance & execution of stages, jobs, tasks\r\n* Detect and report task failures during execution\r\n* Visualize your Spark application execution (via JESL and jkoolcloud integration)\r\n\r\nNOTE: See https://www.jkoolcloud.com and (JESL) http://nastel.github.io/JESL/ to vizualize Spark application execution.\r\n\r\n### Using TNT4J-Spark\r\nTNT4J-Spark is easy, just include a few lines into your application:\r\n```java\r\n...\r\nSparkConf conf = new SparkConf().setAppName(\"my.spark.app\");\r\nJavaSparkContext sc = new JavaSparkContext(conf);\r\n\r\n// add TNT4J-Spark listener to your spark context\r\nsc.addSparkListener(new TNTSparkListener(\"my.spark.app\"));\r\n...\r\n```\r\nMake sure you edit `config/tnt4j.properties` and specify TNT4J configuration for your application `my.spark.app`.\r\n```\r\n; Stanza used for Spark Applications\r\n; replace `my.spark.app` with the name used when creating TNTSparkListener\r\n{\r\n\tsource: my.spark.app\r\n\tsource.factory: com.nastel.jkool.tnt4j.source.SourceFactoryImpl\r\n\tsource.factory.GEOADDR: NewYork\r\n\tsource.factory.DATACENTER: HQDC\r\n\tsource.factory.RootFQN: SERVER=?#DATACENTER=?#GEOADDR=?\t\r\n\t\r\n\ttracker.factory: com.nastel.jkool.tnt4j.tracker.DefaultTrackerFactory\r\n\tdump.sink.factory: com.nastel.jkool.tnt4j.dump.DefaultDumpSinkFactory\r\n\tevent.sink.factory: com.nastel.jkool.tnt4j.sink.FileEventSinkFactory\r\n\r\n\t; Configure default sink filter based on level and time (elapsed/wait)\r\n\tevent.sink.factory.Filter: com.nastel.jkool.tnt4j.filters.EventLevelTimeFilter\r\n\tevent.sink.factory.Filter.Level: TRACE\r\n\t; Uncomment lines below to filter out events based on elapsed time and wait time\r\n\t; Timed event/activities greater or equal to given values will be logged\r\n\t;event.sink.factory.Filter.ElapsedUsec: 100\r\n\t;event.sink.factory.Filter.WaitUsec: 100\r\n\t\r\n\tevent.formatter: com.nastel.jkool.tnt4j.format.SimpleFormatter\r\n\ttracking.selector: com.nastel.jkool.tnt4j.selector.DefaultTrackingSelector\r\n\ttracking.selector.Repository: com.nastel.jkool.tnt4j.repository.FileTokenRepository\r\n}\r\n```\r\nTNT4J-Spark uses TNT4J API to track job execution. Combining TNT4J-Spark with JESL (http://nastel.github.io/JESL/) lets developers stream data collected by TNT4J-Spark into jKool Cloud -- real-time streaming and vizualization platform (see https://www.jkoolcloud.com). \r\n\r\n#### Add the following arguments to your java start-up\r\n```\r\n-Dtnt4j.config=<home>/config/tnt4j.properties -Dtnt4j.token.repository=<home>/config/tnt4j-tokens.properties \r\n```\r\nTo enable automatic application dump add the following arguments:\r\n```\r\n-Dtnt4j.dump.on.vm.shutdown=true -Dtnt4j.dump.on.exception=true -Dtnt4j.dump.provider.default=true \r\n```\r\nOptionally you can add the following parameters to define default data center name and geo location:\r\n```\r\n-Dtnt4j.source.DATACENTER=YourDataCenterName -Dtnt4j.source.GEOADDR=\"Melville,NY\" \r\n```\r\n\r\n## Requirements\r\n* JDK 1.8\r\n* TNT4J (http://nastel.github.io/TNT4J/)\r\n* Apache Spark 1.2.1 or higher (https://spark.apache.org/)\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}